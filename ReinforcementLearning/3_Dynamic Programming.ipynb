{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dynammic Programming</h1>\n",
    "\n",
    "# 0. Policy Evaluation (Prediction)\n",
    "\n",
    "## Enviroment\n",
    "The environment is like, \n",
    "\n",
    "> 0, 1, 2, 3\n",
    "\n",
    "> 4, 5, 6, 7\n",
    "\n",
    "> 8, 9, 10, 11\n",
    "\n",
    "> 12, 13, 14, 15\n",
    "\n",
    "## State\n",
    "For state $s \\in \\{0, 1, ..., 15\\}$, with 0 and 15 are terminal states .\n",
    "\n",
    "## Action\n",
    "\n",
    "The agent can go as one of the actions in $\\{up, down, left, right\\}$.\n",
    "\n",
    "## Transition Probability\n",
    "\n",
    "The transition probability of the agent goes from $s$ to $s'$ will be 1 if $s'$ is the next state of $s$ with action in $\\mathcal{S}$ or $s$ is in the side of the matrix, otherwise 0.\n",
    "\n",
    "## Reward\n",
    "\n",
    "If the next state $s'$ is the terminal state, the reward is 0, otherwise -1.\n",
    "\n",
    "## Policy Evaluation, $V_{\\pi}(s)$\n",
    "\n",
    "+ Initialize\n",
    "\n",
    "> $V(s) = 0, \\forall s \\in \\mathcal{S}^{+}$\n",
    "\n",
    "+ Repeat\n",
    "\n",
    "> $\\Delta \\leftarrow 0$\n",
    "\n",
    "> For each $s \\in \\mathcal{S}$:\n",
    "\n",
    "> $v \\leftarrow V(s)$\n",
    "\n",
    "> $V(s) \\leftarrow \\sum_{a}\\pi(a|s) \\sum_{s', r}p(s', r|s, a)[r + \\gamma V(s')]$\n",
    "\n",
    "> $\\Delta \\leftarrow \\max(\\Delta, |v - V(s)|)$\n",
    "\n",
    "+ until $\\Delta < \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# environment\n",
    "env = np.array([[0, 1, 2, 3], \n",
    "                [4, 5, 6, 7], \n",
    "                [8, 9, 10, 11], \n",
    "               [12, 13, 14, 15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# state \n",
    "s = np.array(range(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transition probability\n",
    "n_s = 16\n",
    "n_a = 4 #actions, 0: up, 1: down, 2: left , 3: right\n",
    "p = np.zeros((n_s, n_a, n_s)) # s, a, s'\n",
    "\n",
    "prob = 1. / 4 #prob is equal for all actions\n",
    "\n",
    "#up \n",
    "for s in range(4):\n",
    "    p[s][0][s] = prob\n",
    "for s in range(4, 16):\n",
    "    p[s][0][s-4]= prob\n",
    "    \n",
    "#down\n",
    "for s in range(12, 16):\n",
    "    p[s][1][s] = prob\n",
    "for s in range(0, 12):\n",
    "    p[s][1][s+4] = prob\n",
    "    \n",
    "# left \n",
    "for s in range(0, 16, 4):\n",
    "    p[s][2][s] = prob\n",
    "for s in range(1,16):\n",
    "    if s % 4 != 0:\n",
    "        p[s][2][s-1] = prob\n",
    "\n",
    "# right\n",
    "for s in range(3, 16, 4):\n",
    "    p[s][3][s] = prob\n",
    "for s in range(0, 16):\n",
    "    if s % 4 != 3:\n",
    "        p[s][3][s+1] = prob\n",
    "        \n",
    "# terminal state\n",
    "for a in range(4):\n",
    "    for s1 in range(16):\n",
    "        p[0][a][s1] = 0\n",
    "        p[15][a][s1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reward function\n",
    "def reward_func(s, a, s1):\n",
    "    if s1 == 0 or s1 == 15:\n",
    "        return 0\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expect_value(s, gamma, V, p):\n",
    "    \"\"\"\n",
    "    s: current state\n",
    "    gamma: discount factor\n",
    "    V: value function\n",
    "    p: transition probability, s, a, s1\n",
    "    \"\"\"\n",
    "    \n",
    "    # pi(a|s) = 1 / n_a, for all actions\n",
    "    \n",
    "    e_v = 0\n",
    "    for s1 in range(16):\n",
    "        for a in range(4):\n",
    "            #pi_s_a = 1. / 4\n",
    "            p_s_a_s1 = p[s][a][s1]\n",
    "            r = reward_func(s, a, s1)\n",
    "            e_v += p_s_a_s1 * (r + gamma * V[s1])\n",
    "\n",
    "    return e_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# value funtion\n",
    "V = np.zeros(16)\n",
    "gamma = 1.0\n",
    "\n",
    "def evaluate_value_func(V, gamma):\n",
    "    delta = 0\n",
    "    for s in range(16):\n",
    "        v = V[s]\n",
    "        V[s] = expect_value(s, gamma, V, p)\n",
    "        delta = max(delta, abs(v - V[s]))\n",
    "    return V, delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 1e10\n",
    "epsilon = 1e-3\n",
    "while delta > epsilon:\n",
    "    V, delta = evaluate_value_func(V, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        , -12.99419182, -18.99164997, -20.99080924,\n",
       "       -12.99419182, -16.9928726 , -18.99226129, -18.99234977,\n",
       "       -18.99164997, -18.99226129, -16.99346994, -12.99512458,\n",
       "       -20.99080924, -18.99234977, -12.99512458,   0.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008407261041938341"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
