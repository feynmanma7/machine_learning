{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Loss Functions</h1>\n",
    "\n",
    "# 0. Logistic Regression\n",
    "\n",
    "## 0.0 Motivation\n",
    "Assume the logits is a linear transformation of input,\n",
    "\n",
    "> $\\log \\frac{p(y=1)}{1-p(y=1)} = w_0 + w_1 x_1 + ... + w_n x_n = W^{T}X$\n",
    "\n",
    "$\\Rightarrow$\n",
    "\n",
    "> $p(y=1) = \\frac{1}{1 + exp\\{-W^T X\\}}$\n",
    "\n",
    "## 0.1 Loss Function\n",
    "\n",
    "### Log-likelihood\n",
    "\n",
    "Assume data are independently identical distributed, likelihood function is, \n",
    "\n",
    "> $L(W) = \\prod_{i=1}^{M} p(Y_i|W)$\n",
    "\n",
    "> $p(Y_i|W) = p(Y_i=1|W)^{\\mathbb{1}(Y_i=1)} (1 - p(Y_i=1|W))^{1 - \\mathbb{1}(Y_i=1)}$\n",
    "\n",
    "If $Y_i = 1$, $\\mathbb{1}(Y_i=1) = 1$, $Y_i = \\mathbb{1}(Y_i=1)$, \n",
    "\n",
    "> $p(Y_i|W) = p(Y_i=1|W)^{Y_i} (1 - p(Y_i=1|W))^{1 - Y_i}$\n",
    "\n",
    "Log-likelihood function is,\n",
    "\n",
    "> $l(W) = \\log L(W) = \\sum_{i=1}^{M} Y_i \\log p(Y_i=1|W) + (1 - Y_i) \\log (1 - p(Y_i=1|W))$\n",
    "\n",
    "### Loss Fuction\n",
    "\n",
    "Use the average negative log-likelihood as loss function, \n",
    "\n",
    "> $J(W) = - \\frac{1}{M} l(W) = - \\frac{1}{M} \\sum_{i=1}^{M} Y_i \\log p(Y_i=1|W) + (1 - Y_i) \\log (1 - p(Y_i=1|W))$\n",
    "\n",
    "## 0.2 Optimization\n",
    "\n",
    "Compute the gradient of $J(W)$ with respect to $w_j$, \n",
    "\n",
    "> $\\frac{\\partial{J(W)}}{\\partial{w_j}} = \n",
    "- \\frac{1}{M} \\sum_{i=1}^M Y_i \\frac{1}{p}p' + (1 - Y_i) \\frac{1}{1-p}(-p')$\n",
    "\n",
    "> $p' = p(1-p)x_j$\n",
    "\n",
    "$\\Rightarrow$\n",
    "\n",
    "> $\\frac{\\partial{J(W)}}{\\partial{w_j}} = - \\frac{1}{M} \\sum_{i=1}^M\n",
    "(Y_i - p_i)x^{(i)}_j$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Support Vector Machines\n",
    "\n",
    "## 1.0 Motivation\n",
    "\n",
    "For datasets $\\{X, y\\}, y = \\{+1, -1\\}$, we want to classify them by a hyper-line $WX + b = 0$,\n",
    "\n",
    "assume the nearest point lies on the line $WX + b = C, C > 0$, without loss of generality, let $C$ be 1. \n",
    "\n",
    "We obtain that, \n",
    "\n",
    "> $WX + b \\ge +1$, if $y = +1$\n",
    "\n",
    "> $WX + b \\le -1$, if $y = -1$\n",
    "\n",
    "$\\Rightarrow$\n",
    "\n",
    "> $y(WX + b) \\ge 1$\n",
    "\n",
    "The distance between line (1) $Ax + By + C_1 = 0$ and line (2) $Ax + By + C_2 = 0$ is, \n",
    "\n",
    "> $\\frac{|C_1 - C_2|}{\\sqrt{A^2 + B^2}}$\n",
    "\n",
    "\n",
    "Thus, the distance between line 1 $WX + b = +1$ and line 2 $WX + b = -1$ is, \n",
    "\n",
    "> $\\frac{(+1) - (-1)}{\\sqrt{W^2}} = \\frac{2}{||W||_2}$\n",
    "\n",
    "### Maximium Margin\n",
    "\n",
    "To reduce the ambiguity of tesing, we want to <b>maximize the distance</b> $\\frac{2}\n",
    "{||W||_2}$ w.r.t $w$, which is same with $\\frac{1}{||W||_2}$.\n",
    "\n",
    "### Hinge Loss\n",
    "\n",
    "+ If $y = +1$, but $WX + b < 1$, loss can be $1 - (WX + b)$, \n",
    "\n",
    "+ If $y = -1$, but $WX + b > -1$, loss can be $(WX + b) + 1$, \n",
    "\n",
    "> $loss = max(0, 1 - y(WX + b))$\n",
    "\n",
    "## 1.1 Loss Function\n",
    "\n",
    "### Maximum Margin\n",
    "Loss function will be, \n",
    "> $J(W, b) = \\arg\\min_{W, b} ||W||_2$\n",
    "\n",
    "> s.t. $y_i(WX_i + b) \\ge 1$\n",
    "\n",
    "For slack circumstances, the loss function could be, \n",
    "\n",
    "> $J(W, b) = \\arg\\min_{W, b} ||W||_2 + C \\sum_{i=1}^M \\xi_i$\n",
    "\n",
    "> s.t. $y_i (WX_i + b) \\ge 1 - \\xi_i$\n",
    "\n",
    "> $\\xi_i \\ge 0$\n",
    "\n",
    "$C$ is the penalty factor for outliers.\n",
    "\n",
    "### Hinge Loss\n",
    "\n",
    "> $J(W, b) = \\arg\\min_{W, b} \\frac{1}{2} ||W||_2 + C \\sum_{i=1}^M max(1 - y_i (WX_i + b)) $\n",
    "\n",
    "## 1.2 Optimization\n",
    "\n",
    "It's a contraint optimization problem.\n",
    "\n",
    "### Primal Problem\n",
    "\n",
    "The constaint optimization problem is, \n",
    "\n",
    "> $\\min_x f_0(x)$\n",
    "\n",
    "> s.t. $f_i(x) \\le 0, i = 1,2, ..., m$\n",
    "\n",
    "> $h_i(x) = 0, i = 1, 2, ..., n$\n",
    "\n",
    "where $f_i(x), i = 0, 1, ..., m$ are convex functions, \n",
    "\n",
    "$h_i(x), i = 1, 2, ..., n$ are affine functions.\n",
    "\n",
    "Define the <b>Lagrange</b> problems, \n",
    "\n",
    "> $L(x, \\alpha, \\beta) = f_0(x) + \\sum_{i=1}^m \\alpha_i f_i(x) + \\sum_{i=1}^n \\beta_i h_i(x)$\n",
    "\n",
    "The primal problem can be writed as, \n",
    "\n",
    "> $\\min_x \\max_{\\alpha \\ge 0, \\beta} L(x, \\alpha, \\beta)$\n",
    "\n",
    "If all of the constaints are satisfied, the primal object function will be obtained.\n",
    "\n",
    "### Dual Problem\n",
    "\n",
    "> $\\max_{\\alpha \\ge 0, \\beta} \\min_x L(x, \\alpha, \\beta)$\n",
    "\n",
    "$\\min_x L(x, \\alpha, \\beta)$ is a lower bound of $L$, \n",
    "\n",
    "$\\max_{\\alpha \\ge 0, \\beta} \\min_x L(x, \\alpha, \\beta)$ is the maximum lower bound of primal problem.\n",
    "\n",
    "### KKT Conditions\n",
    "\n",
    "If the primal problem is a convex optimization problem, the optimization solution satisfies the KKT conditions.\n",
    "\n",
    "+ Primal feasibility\n",
    "\n",
    "> $f_i(x) \\le 0, i = 1, 2, ..., m$\n",
    "\n",
    "> $h_i(x) = 0, i = 1, 2, ..., n$\n",
    "\n",
    "+ Dual feasibility \n",
    "\n",
    "> $\\alpha_i \\ge 0, i = 1, 2, ..., m$\n",
    "\n",
    "+ Complementary slackness\n",
    "\n",
    "> $\\alpha_i f_i(x) = 0, i = 1, 2, ..., m$\n",
    "\n",
    "+ Stationarity\n",
    "\n",
    "> $\\nabla f_0(x) + \\sum_{i=1}^m \\alpha_i \\nabla f_i(x) + \\sum_{i=1}^n \\beta_i h_i(x) = 0$\n",
    "\n",
    "## 1.3 SVM Solution\n",
    "\n",
    "For slackness problem, \n",
    "\n",
    "> $J(W, b) = \\min_{W, b, \\xi} \\frac{1}{2}||W||_2 + C \\sum_{i=1}^m \\xi_i $\n",
    "\n",
    "> s.t. $y_i (WX_i + b) \\ge 1 - \\xi_i$\n",
    "\n",
    "> $\\xi_i \\ge 0$\n",
    "\n",
    "Lagrange problem is, \n",
    "\n",
    "> $L(W, b, \\xi, \\alpha, \\beta) = \\frac{1}{2} ||W||_2 + C \\sum_{i=1}^m \\xi_i - \n",
    "\\sum_{i=1}^m \\alpha_i (y_i (WX_i + b) - 1 + \\xi_i) - \n",
    "\\sum_{i=1}^m \\beta_i \\xi_i$\n",
    "\n",
    "Primal problem, \n",
    "\n",
    "> $\\min_{W, b, \\xi} \\max_{\\alpha \\ge 0, \\beta \\ge 0} L(W, b, \\xi, \\alpha, \\beta)$\n",
    "\n",
    "Dual problem, \n",
    "\n",
    "> $g(W, b, \\xi, \\alpha, \\beta) = \\max_{\\alpha \\ge 0, \\beta \\ge 0} \\min_{W, b, \\xi}  L(W, b, \\xi, \\alpha, \\beta)$\n",
    "\n",
    "### Step 1, solve the minimum problem\n",
    "\n",
    "Compute the partial gradient of $L$ w.r.t $W, b, \\xi$, \n",
    "\n",
    "> $\\frac{\\partial{L}}{\\partial{W}} = W - \\sum_{i=1}^m \\alpha_i y_i X_i = 0 \\Rightarrow W = \\sum_{i=1}^m \\alpha_i y_i X_i, w_j = \\sum_{i=1}^m \\alpha_i y_i x_{i,j}$ \n",
    "\n",
    "> $\\frac{\\partial{L}}{\\partial{b}} = 0 \\Rightarrow \\sum_{i=1}^m \\alpha_i y_i = 0$\n",
    "\n",
    "> $\\frac{\\partial{L}}{\\partial{\\xi}} = 0 \\Rightarrow C - \\alpha_i - \\beta_i = 0$\n",
    "\n",
    "### Step 2, solve the maximum problem\n",
    "\n",
    "Plug the results of step 1 into $g$, \n",
    "\n",
    "> $g = \\max_{\\alpha \\ge 0, \\beta \\ge 0} \n",
    "\\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^m \\alpha_i \\alpha_j y_i y_j (X_i X_j) - \\sum_{i=1}^m \\alpha_i$\n",
    "\n",
    "> $= \\min_{\\alpha \\ge 0, \\beta \\ge 0} - \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^m \\alpha_i \\alpha_j y_i y_j (X_i X_j) + \\sum_{i=1}^m \\alpha_i$\n",
    "\n",
    "> s.t. $\\sum_{i=1}^m \\alpha_i y_i = 0$\n",
    "\n",
    "> $C - \\alpha_i - \\beta_i = 0, i = 1, 2, ..., m$\n",
    "\n",
    "> $\\alpha_i \\ge 0$\n",
    "\n",
    "> $\\beta_i \\ge 0$\n",
    "\n",
    "The problem can be rewrited as, \n",
    "\n",
    "> $= \\min_{\\alpha \\ge 0} - \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^m \\alpha_i \\alpha_j y_i y_j (X_i X_j) + \\sum_{i=1}^m \\alpha_i$\n",
    "\n",
    "> s.t. $\\sum_{i=1}^m \\alpha_i y_i = 0$\n",
    "\n",
    "> $0 \\le \\alpha_i \\le C$\n",
    "\n",
    "The primal problem is a $\\min\\max$ problem of the Lagrange of $g$.\n",
    "\n",
    "> $\\min_{\\alpha} \\max_{\\gamma, \\theta, \\lambda} - \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^m \\alpha_i \\alpha_j y_i y_j (X_i X_j) + \\sum_{i=1}^m \\alpha_i \n",
    "+ \\gamma \\sum_{i=1}^{m} a_i y_i - \\sum_{i=1}^m \\theta_i \\alpha_i\n",
    "+ \\sum_{i=1}^m \\lambda_i (\\alpha_i - C)$\n",
    "\n",
    "The dual problem is, \n",
    "\n",
    "> $\\max_{\\gamma, \\theta, \\lambda} \\min_{\\alpha}  - \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^m \\alpha_i \\alpha_j y_i y_j (X_i X_j) + \\sum_{i=1}^m \\alpha_i \n",
    "+ \\gamma \\sum_{i=1}^{m} a_i y_i - \\sum_{i=1}^m \\theta_i \\alpha_i\n",
    "+ \\sum_{i=1}^m \\lambda_i (\\alpha_i - C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the partial gradient to satisfy the KKT conditions, \n",
    "\n",
    "> $\\sum_{i=1}^m \\alpha_i y_i = 0$\n",
    "\n",
    "> $\\theta_i \\alpha_i = 0$\n",
    "\n",
    "> $\\lambda_i (\\alpha_i - C) = 0$ \n",
    "\n",
    "> $\\frac{\\partial{f}}{\\partial{\\alpha_i}} = 0 \\Rightarrow \n",
    "-\\frac{1}{2} \\sum_{j=1}^m \\alpha_j y_i y_j (X_i X_j) + 1 = 0$\n",
    "\n",
    "We need to compute $\\{\\alpha_1, \\alpha_2, ..., \\alpha_m\\}, 0 < \\alpha_i < C$, then\n",
    "\n",
    "> $W = \\sum_{i=1}^m \\alpha_i y_i X_i$\n",
    "\n",
    "For <b>support vectors</b> which lines on $y_i(WX_i + b) = 1$, $\\xi_i = 0, i \\in \\mathcal{S}$, \n",
    "\n",
    "> $y_i(WX_i + b) = 1, i \\in \\mathcal{S}$\n",
    "\n",
    "Take a trick of $y_i = \\pm 1$, \n",
    "\n",
    "> $WX_i + b = y_i$\n",
    "\n",
    "> $\\sum_{i=1}^m WX_i + b = \\sum_{i=1}^m y_i$\n",
    "\n",
    "> $b = \\frac{1}{m} \\sum_{i=1}^m (y_i - WX_i), i \\in \\mathcal{S}$\n",
    "\n",
    "### Choose support vectors\n",
    "\n",
    "For $y = +1$, $W^* X_i + b = +1, i = \\min_{i} W^* X_i$,\n",
    "\n",
    "for $y = -1$, $W^* X_i + b = -1, i = \\max_{i} W^* X_i$, \n",
    "\n",
    "> $b = -\\frac{min_{i,y_i=+1}W^* X_i + max_{i,y_i=-1}W^* X_i}{2}$\n",
    "\n",
    "### Predict\n",
    "\n",
    "> $y = sign(WX + b) = sign(\\sum_{i=1}^m \\alpha_i y_i <X_i, X>)$\n",
    "\n",
    "## 1.4 SMO\n",
    "\n",
    "The problem is to compute, \n",
    "\n",
    "> $W = \\sum_{i=1}^m \\alpha_i y_i X_i$\n",
    "\n",
    "We have already obtain, \n",
    "\n",
    "> $\\sum_{i=1}^m \\alpha_i y_i = 0$\n",
    "\n",
    "> $-\\frac{1}{2} \\sum_{j=1}^m \\alpha_j y_i y_j (X_i X_j) + 1 = 0$\n",
    "\n",
    "We cannot get $\\alpha_i$ according to equations above cause they convey the same information ($\\alpha$ and $y$ always has the same index). \n",
    "\n",
    "Thus, we cannot use the <b>coordinate descent</b> algorighms \n",
    "which update one parameter a time.\n",
    "\n",
    "The SMO algorithm update two parametes a time while keep other parameters fixed.\n",
    "\n",
    "For example, first we want to optimize $\\alpha_1$ and $\\alpha_2$.\n",
    "\n",
    "> $\\alpha_1 y_1 + \\alpha_2 y_2 = - \\sum_{i=3}^m \\alpha_i y_i$\n",
    "\n",
    "Compute $- \\sum_{i=3}^m \\alpha_i y_i$ and denote it as $c$.\n",
    "\n",
    "> $\\alpha_1 y_1 + \\alpha_2 y_2 = c \\Rightarrow \\alpha_1 = y_1(c - \\alpha_2 y_2)$, note the trick of $y_1 = \\pm 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dual problem becomes a quadratic problem of $\\alpha_2$, which is easy to compute.\n",
    "\n",
    "> $g = \\min_{\\alpha \\ge 0, \\beta \\ge 0} - \\frac{1}{2} \\sum_{i=1}^m \\sum_{j=1}^m \\alpha_i \\alpha_j y_i y_j (X_i X_j) + \\sum_{i=1}^m \\alpha_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Kernel Trick\n",
    "\n",
    "If the problem is not linearly classified, we can map the input to high dimension spaces which is linearly classified, which means we let $X = \\Phi(X)$.\n",
    "\n",
    "When predicting, \n",
    "\n",
    "> $y = sign(WX + b) = \\sum_{i=1}^m \\alpha_i y_i <\\Phi(X_i), \\Phi(X)>$\n",
    "\n",
    "We use a kernel function to compute the inner product of $\\Phi(X_i)$ and $\\Phi(X)$ without actually do the complex mapping operations.\n",
    "\n",
    "### Some common kernel methods\n",
    "\n",
    "#### Linear Kernel\n",
    "> $K(x, x') = x * x'$\n",
    "\n",
    "#### Gaussian (RBF) Kernel\n",
    "> $K(x, x') = exp\\{-\\frac{||x-x'||^2}{\\sigma^2}\\}$\n",
    "\n",
    "#### Sigmoid Kernel\n",
    "> $K(x, x') = tanh(\\eta<x, x'> + \\theta)$\n",
    "\n",
    "#### Polynomial Kernel\n",
    "> $K(x, x') = (x*x' + 1)^d$\n",
    "\n",
    "#### Self-defined Kernel\n",
    "According to the Mercier Theorem, every semi-positive function can be a valid kernel function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. KMeans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
